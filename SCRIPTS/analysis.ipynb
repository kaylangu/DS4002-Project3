{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39be0b3a-6480-42c9-9d28-896e852f4e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import deeplake\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "import time\n",
    "import functools\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 12)\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438e67a3-6fea-45e8-844d-8c79ce6859b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/wiki-art loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Load in style images dataset\n",
    "ds = deeplake.load('hub://activeloop/wiki-art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378e3547-987e-4c3d-a997-43a83dd2a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for style labels\n",
    "style_mapping = {\n",
    "    0: \"abstract_expressionism\",\n",
    "    1: \"action_painting\",\n",
    "    2: \"analytical_cubism\",\n",
    "    3: \"art_nouveau_modern\",\n",
    "    4: \"baroque\",\n",
    "    5: \"color_field_painting\",\n",
    "    6: \"contemporary_realism\",\n",
    "    7: \"cubism\",\n",
    "    8: \"early_renaissance\",\n",
    "    9: \"expressionism\",\n",
    "    10: \"fauvism\",\n",
    "    11: \"high_renaissance\",\n",
    "    12: \"impressionism\",\n",
    "    13: \"mannerism_late_renaissance\",\n",
    "    14: \"minimalism\",\n",
    "    15: \"naive_art_primitivism\",\n",
    "    16: \"new_realism\",\n",
    "    17: \"northern_renaissance\",\n",
    "    18: \"pointillism\",\n",
    "    19: \"pop_art\",\n",
    "    20: \"post_impressionism\",\n",
    "    21: \"realism\",\n",
    "    22: \"rococo\",\n",
    "    23: \"romanticism\",\n",
    "    24: \"symbolism\",\n",
    "    25: \"synthetic_cubism\",\n",
    "    26: \"ukiyo_e\"\n",
    "}\n",
    "\n",
    "output_base_folder = \"./wiki_art_images\"\n",
    "images_per_style = 50\n",
    "# Create folder for each style\n",
    "for style_label, style_name in style_mapping.items():\n",
    "    style_folder = os.path.join(output_base_folder, style_name)\n",
    "    os.makedirs(style_folder, exist_ok=True)\n",
    "    \n",
    "    #Filter dataset\n",
    "    indices = [i for i, label in enumerate(ds['labels']) if label.numpy() == style_label]\n",
    "    # Randomly select images of each type\n",
    "    random_indices = random.sample(indices, min(len(indices), images_per_style))\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        image_array = ds['images'][idx].numpy()\n",
    "        \n",
    "        image = Image.fromarray((image_array * 255).astype(np.uint8))\n",
    "\n",
    "        image.save(os.path.join(style_folder, f\"{style_name}_{i+1}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be072ca-2a35-4878-8b65-6668f065a005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert tensor to image\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4091fde3-4622-4e69-830d-206ed23e4cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to laod an image\n",
    "def load_img(path_to_img):\n",
    "    max_dim = 512\n",
    "    img = tf.io.read_file(path_to_img)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb70a4d-946f-41fe-b789-ff51b02c47f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for pretrained VGG19 model\n",
    "def vgg_layers(layer_names):\n",
    "    \"\"\" Creates a VGG model that returns a list of intermediate output values.\"\"\"\n",
    "    # Load our model. Load pretrained VGG, trained on ImageNet data\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "  \n",
    "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b089c84-3c3c-4c09-9ac6-2fda7d4847be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Style content model\n",
    "class StyleContentModel(tf.keras.models.Model):\n",
    "    def __init__(self, style_layers, content_layers):\n",
    "        super(StyleContentModel, self).__init__()\n",
    "        self.vgg = vgg_layers(style_layers + content_layers)\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.num_style_layers = len(style_layers)\n",
    "        self.vgg.trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"Expects float input in [0,1]\"\n",
    "        inputs = inputs*255.0\n",
    "        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "        outputs = self.vgg(preprocessed_input)\n",
    "        style_outputs, content_outputs = (outputs[:self.num_style_layers],\n",
    "                                          outputs[self.num_style_layers:])\n",
    "\n",
    "        style_outputs = [gram_matrix(style_output) \n",
    "                         for style_output in style_outputs]\n",
    "\n",
    "        content_dict = {content_name: value\n",
    "                        for content_name, value\n",
    "                        in zip(self.content_layers, content_outputs)}\n",
    "\n",
    "        style_dict = {style_name: value\n",
    "                      for style_name, value\n",
    "                      in zip(self.style_layers, style_outputs)}\n",
    "\n",
    "        return {'content': content_dict, 'style': style_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7348860e-bf02-4809-b2e0-aa04b7438433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate gram matrix\n",
    "def gram_matrix(input_tensor):\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "    return result/(num_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bddc7975-8280-4bd9-bd87-54cf682fab56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for loss calculation\n",
    "def style_content_loss(outputs):\n",
    "    style_outputs = outputs['style']\n",
    "    content_outputs = outputs['content']\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name] - style_targets[name])**2) for name in style_outputs.keys()])\n",
    "    style_loss *= style_weight / num_style_layers\n",
    "\n",
    "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name] - content_targets[name])**2) for name in content_outputs.keys()])\n",
    "    content_loss *= content_weight / num_content_layers\n",
    "    return style_loss + content_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc29389d-1868-46e9-ac19-d3af77df1799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to clip image values to a valid range\n",
    "def clip_0_1(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d059942f-0bb1-446b-8430-02249a78cdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training step function\n",
    "@tf.function()\n",
    "def train_step(image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(image)\n",
    "        loss = style_content_loss(outputs)\n",
    "        loss += total_variation_weight*tf.image.total_variation(image)\n",
    "\n",
    "    grad = tape.gradient(loss, image)\n",
    "    opt.apply_gradients([(grad, image)])\n",
    "    image.assign(clip_0_1(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07cdf2a1-f09c-4a09-af94-4664d6a04ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Style transfer parameters\n",
    "content_layers = ['block5_conv2'] \n",
    "\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1']\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)\n",
    "\n",
    "style_weight=1e-2\n",
    "content_weight=1e4\n",
    "total_variation_weight=30\n",
    "epochs = 2\n",
    "steps_per_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97c81e1f-9b44-4e2a-b059-f2dcecec3975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732291918.311350  209843 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Intializing the model\n",
    "extractor = StyleContentModel(style_layers, content_layers)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "105299ef-0f74-433f-bf61-2b2e2c0bc422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_images_folder = \"./Images\"\n",
    "style_images_base_folder = \"./wiki_art_images\"\n",
    "\n",
    "content_image_paths = [os.path.join(content_images_folder, fname)\n",
    "                       for fname in os.listdir(content_images_folder)\n",
    "                       if fname.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "style_types = [d for d in os.listdir(style_images_base_folder) if os.path.isdir(os.path.join(style_images_base_folder, d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6966f5a-d964-40f0-adf0-eb9d29842f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_base_folder = \"./style_images\"\n",
    "for content_path in content_image_paths:\n",
    "    content_name = os.path.splitext(os.path.basename(content_path))[0]\n",
    "    content_output_folder = os.path.join(output_base_folder, content_name)\n",
    "    os.makedirs(content_output_folder, exist_ok=True)\n",
    "    \n",
    "    content_image = load_img(content_path)\n",
    "    \n",
    "    step = 0\n",
    "    for style_type in style_types:\n",
    "        style_type_folder = os.path.join(content_output_folder, style_type)\n",
    "        os.makedirs(style_type_folder, exist_ok=True)\n",
    "\n",
    "        style_images = [\n",
    "            os.path.join(style_images_base_folder, style_type, fname)\n",
    "            for fname in os.listdir(os.path.join(style_images_base_folder, style_type))\n",
    "            if fname.lower().endswith(('png', 'jpg', 'jpeg'))\n",
    "        ]\n",
    "\n",
    "        for i, style_path in enumerate(style_images):\n",
    "            style_image = load_img(style_path)\n",
    "\n",
    "            # Perform style transfer\n",
    "            style_targets = extractor(style_image)['style']\n",
    "            content_targets = extractor(content_image)['content']\n",
    "            stylized_image = tf.Variable(content_image)\n",
    "\n",
    "            # Training loop\n",
    "            for n in range(epochs):  # Adjust epochs and steps_per_epoch\n",
    "                for m in range(steps_per_epoch):\n",
    "                    train_step(stylized_image)\n",
    "\n",
    "            # Save the stylized image\n",
    "            output_image = tensor_to_image(stylized_image)\n",
    "            output_image.save(os.path.join(style_type_folder, f\"{style_type}_{i+1}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3deb9-beb7-44f9-829d-b535dea64e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
